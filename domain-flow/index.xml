<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Domain Flow Algorithms</title>
    <link>https://stillwater-sc.github.io/domain-flow/</link>
    <description>Recent content on Domain Flow Algorithms</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>theo@stillwater-sc.com (Stillwater Supercomputing, Inc.)</managingEditor>
    <webMaster>theo@stillwater-sc.com (Stillwater Supercomputing, Inc.)</webMaster><atom:link href="https://stillwater-sc.github.io/domain-flow/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Basic Linear Algebra</title>
      <link>https://stillwater-sc.github.io/domain-flow/blas/</link>
      <pubDate>Wed, 15 Feb 2017 07:54:08 -0500</pubDate>
      <author>theo@stillwater-sc.com (Stillwater Supercomputing, Inc.)</author>
      <guid>https://stillwater-sc.github.io/domain-flow/blas/</guid>
      <description>Chapter 3 Linear Algebra: the basics Basic Linear Algebra Subroutines are an historically significant set of functions that encapsulate the basic building blocks of a large collection of linear algebra algorithms and implementation.
The BLAS library has proven to be a very productive mechanism to create and disseminate highly optimized numerical libraries to a plethora of computer architectures and machines. Writing high-performance linear algebra algorithms turns out to be a tenacious problem, but since linear algebra operations are essential</description>
    </item>
    
    <item>
      <title>Linear Solvers</title>
      <link>https://stillwater-sc.github.io/domain-flow/linearsolvers/</link>
      <pubDate>Wed, 15 Feb 2017 07:54:08 -0500</pubDate>
      <author>theo@stillwater-sc.com (Stillwater Supercomputing, Inc.)</author>
      <guid>https://stillwater-sc.github.io/domain-flow/linearsolvers/</guid>
      <description>Chapter 6 Linear Solvers Solving systems of equations is the impetus for the class of algorithms called linear solvers.</description>
    </item>
    
    <item>
      <title>Matrix Factorization</title>
      <link>https://stillwater-sc.github.io/domain-flow/factorization/</link>
      <pubDate>Wed, 15 Feb 2017 07:54:08 -0500</pubDate>
      <author>theo@stillwater-sc.com (Stillwater Supercomputing, Inc.)</author>
      <guid>https://stillwater-sc.github.io/domain-flow/factorization/</guid>
      <description>Chapter 4 Matrix Factorization Matrix factorizations are the work horse of linear algebra applications. Factorizations create equivalences that improve the usability or robustness of an algorithm.</description>
    </item>
    
    <item>
      <title>Matrix Kernels</title>
      <link>https://stillwater-sc.github.io/domain-flow/matrixkernels/</link>
      <pubDate>Wed, 15 Feb 2017 07:54:08 -0500</pubDate>
      <author>theo@stillwater-sc.com (Stillwater Supercomputing, Inc.)</author>
      <guid>https://stillwater-sc.github.io/domain-flow/matrixkernels/</guid>
      <description>Chapter 5 Matrix Kernels Matrix Kernels are important to characterize and classify the underlying system of equations. Identifying singularity, and quantifying the null-space of a matrix are key operators before we can try to solve systems of equations.</description>
    </item>
    
    <item>
      <title>Elements of Good Design</title>
      <link>https://stillwater-sc.github.io/domain-flow/design/</link>
      <pubDate>Wed, 15 Feb 2017 07:42:59 -0500</pubDate>
      <author>theo@stillwater-sc.com (Stillwater Supercomputing, Inc.)</author>
      <guid>https://stillwater-sc.github.io/domain-flow/design/</guid>
      <description>Chapter 2 Elements of Good Design For sixty years, we have been optimizing for sequential computation. The best algorithms for sequential execution are those that minimize the number of operations to yield results. Computational complexity theory is well-aligned with this quest, but any performance-minded algorithm designer knows that the best theoretical algorithms are not necessarily the fastest when executed on real hardware. The difference is typically caused by the trade-off sequential algorithms have to make between computation and accessing memory.</description>
    </item>
    
    <item>
      <title>Introduction</title>
      <link>https://stillwater-sc.github.io/domain-flow/introduction/</link>
      <pubDate>Wed, 15 Feb 2017 06:49:44 -0500</pubDate>
      <author>theo@stillwater-sc.com (Stillwater Supercomputing, Inc.)</author>
      <guid>https://stillwater-sc.github.io/domain-flow/introduction/</guid>
      <description>Getting Started Introduction to Domain Flow Algorithms Domain Flow algorithms are parallel algorithms that incorporate the constraints of space and time. By honoring the delay that is inherent to exchanging information between two spatially separate computation or storage sites, domain flow algorithms can improve performance and energy efficiency compared to sequential programming models that depend on (globally addressable) random access memory.
High-performance, low-latency, energy-efficient computation is particularly important for the emerging application class of autonomous intelligent systems.</description>
    </item>
    
  </channel>
</rss>
